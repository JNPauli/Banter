{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2829071d",
   "metadata": {},
   "source": [
    "## **0. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5adce5",
   "metadata": {},
   "source": [
    "This notebook follows after the \"General Linear Model.iypnb\" notebook. Aim of this notebook is to conduct the support vector machine. For now, we have 26 z-maps, so one for each contrast, for each session, i.e. 4 * 26 z-maps. We will train the SVM on two sessions and then test the SVM on the remaining two sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a86f39",
   "metadata": {},
   "source": [
    "## **1. Masking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e687e3",
   "metadata": {},
   "source": [
    "First we will need to load the mask. The masks needs to be fetched from the openneuro dataset. This is done with *datalad*.\n",
    "\n",
    "We cd into the local dataset directory and then use the command:\n",
    "\n",
    "datalad get sourcedata/sub-01/anat.\n",
    "\n",
    "The masks are bi-lateral organised, meaning one mask per hemisphere. For starters, the higher visual cortex (HVC) will be the first mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ae562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-01_mask_LH_FFA.nii.gz',\n",
       " 'sub-01_mask_LH_hV4.nii.gz',\n",
       " 'sub-01_mask_LH_HVC.nii.gz',\n",
       " 'sub-01_mask_LH_LOC.nii.gz',\n",
       " 'sub-01_mask_LH_PPA.nii.gz',\n",
       " 'sub-01_mask_LH_V1d.nii.gz',\n",
       " 'sub-01_mask_LH_V1v.nii.gz',\n",
       " 'sub-01_mask_LH_V2d.nii.gz',\n",
       " 'sub-01_mask_LH_V2v.nii.gz',\n",
       " 'sub-01_mask_LH_V3d.nii.gz',\n",
       " 'sub-01_mask_LH_V3v.nii.gz',\n",
       " 'sub-01_mask_RH_FFA.nii.gz',\n",
       " 'sub-01_mask_RH_hV4.nii.gz',\n",
       " 'sub-01_mask_RH_HVC.nii.gz',\n",
       " 'sub-01_mask_RH_LOC.nii.gz',\n",
       " 'sub-01_mask_RH_PPA.nii.gz',\n",
       " 'sub-01_mask_RH_V1d.nii.gz',\n",
       " 'sub-01_mask_RH_V1v.nii.gz',\n",
       " 'sub-01_mask_RH_V2d.nii.gz',\n",
       " 'sub-01_mask_RH_V2v.nii.gz',\n",
       " 'sub-01_mask_RH_V3d.nii.gz',\n",
       " 'sub-01_mask_RH_V3v.nii.gz']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/jpauli/ds001506/sourcedata/sub-01/anat\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33619ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b81c9",
   "metadata": {},
   "source": [
    "We can see that there are 22 masks in total, 11 for each hemisphere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a86990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img_path = '/home/jpauli/ds001506/sourcedata/sub-01/anat'\n",
    "mask_img_L = os.path.join(mask_img_path,'sub-01_mask_LH_HVC.nii.gz')\n",
    "mask_img_R = 'sub-01_mask_RH_HVC.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "867fcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_filename_path = '/mnt/c/Users/janos/git/sessions/z_maps_2'\n",
    "func_filename =  os.path.join(func_filename_path,'02_active -1443537.0_z_map.nii.gz')\n",
    "os.chdir('/mnt/c/Users/janos/git/sessions/z_maps_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25fd6518",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Nifti1Image' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_470/3709147787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunc_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Nifti1Image' object is not callable"
     ]
    }
   ],
   "source": [
    "func_mean = mean_img(func_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85fe3671",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mask affine: \n[[-1.99986243e+00 -2.03839540e-02 -1.16112223e-02  1.01610313e+02]\n [-1.92472935e-02  1.99166536e+00 -1.81379184e-01 -1.09106407e+02]\n [-1.34115219e-02  1.81254983e-01  1.99172449e+00 -7.27547607e+01]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n is different from img affine:\n[[-2.00000000e+00  0.00000000e+00  6.89032165e-15  9.74524002e+01]\n [ 0.00000000e+00 -1.75182104e+00 -9.64947224e-01  9.18372650e+01]\n [ 0.00000000e+00 -9.64947224e-01  1.75182104e+00  7.57828140e+00]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_470/3944618410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmasked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_img_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# masked_data shape is (timepoints, voxels). We can plot the first 150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# timepoints from two voxels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36mapply_mask\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    756\u001b[0m     return _apply_mask_fmri(imgs, mask_img, dtype=dtype,\n\u001b[1;32m    757\u001b[0m                             \u001b[0msmoothing_fwhm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmoothing_fwhm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                             ensure_finite=ensure_finite)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36m_apply_mask_fmri\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    782\u001b[0m         raise ValueError('Mask affine: \\n%s\\n is different from img affine:'\n\u001b[1;32m    783\u001b[0m                          '\\n%s' % (str(mask_affine),\n\u001b[0;32m--> 784\u001b[0;31m                                    str(imgs_img.affine)))\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimgs_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mask affine: \n[[-1.99986243e+00 -2.03839540e-02 -1.16112223e-02  1.01610313e+02]\n [-1.92472935e-02  1.99166536e+00 -1.81379184e-01 -1.09106407e+02]\n [-1.34115219e-02  1.81254983e-01  1.99172449e+00 -7.27547607e+01]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n is different from img affine:\n[[-2.00000000e+00  0.00000000e+00  6.89032165e-15  9.74524002e+01]\n [ 0.00000000e+00 -1.75182104e+00 -9.64947224e-01  9.18372650e+01]\n [ 0.00000000e+00 -9.64947224e-01  1.75182104e+00  7.57828140e+00]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]"
     ]
    }
   ],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "masked_data = apply_mask(func_filename, mask_img_L)\n",
    "\n",
    "# masked_data shape is (timepoints, voxels). We can plot the first 150\n",
    "# timepoints from two voxels\n",
    "\n",
    "# And now plot a few of these\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(masked_data[:150, :2])\n",
    "plt.xlabel('Time [TRs]', fontsize=16)\n",
    "plt.ylabel('Intensity', fontsize=16)\n",
    "plt.xlim(0, 150)\n",
    "plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e060577",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/janos/git/sessions/z_maps_2')\n",
    "a = '02_active -1443537.0_z_map.nii.gz'\n",
    "#from nilearn.image import mean_img \n",
    "#from nilearn.plotting import plot_img\n",
    "#mean_img = mean_img(a)\n",
    "#plot_img(mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e9793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_ai",
   "language": "python",
   "name": "neuro_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
